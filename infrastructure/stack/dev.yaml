AWSTemplateFormatVersion: 2010-09-09
Description: Airflow server backed by Postgres RDS
Parameters:
  Application:
    Type: String
    Default: aws_wemoexport_processor
  Environment:
    Type: String
    Default: dev
  KeyName:
    Description: >-
      Name of an existing EC2 KeyPair to enable SSH access into the Airflow web
      server
    Type: 'AWS::EC2::KeyPair::KeyName'
    ConstraintDescription: Must be the name of an existing EC2 KeyPair
  S3BucketName:
    Description: >-
      REQUIRED - A new S3 Bucket name. This bucket will be used by Sagemaker for
      reading and writing model artifacts or hosting data
    Type: String
    AllowedPattern: .+
Mappings:
  RegionMap:
    ap-northeast-1:
      AMI: ami-06cd52961ce9f0d85
    ap-northeast-2:
      AMI: ami-0a10b2721688ce9d2
    ap-northeast-3:
      AMI: ami-0d98120a9fb693f07
    ap-south-1:
      AMI: ami-0912f71e06545ad88
    ap-southeast-1:
      AMI: ami-08569b978cc4dfa10
    ap-southeast-2:
      AMI: ami-09b42976632b27e9b
    ca-central-1:
      AMI: ami-0b18956f
    eu-central-1:
      AMI: ami-0233214e13e500f77
    eu-west-1:
      AMI: ami-047bb4163c506cd98
    eu-west-2:
      AMI: ami-f976839e
    eu-west-3:
      AMI: ami-0ebc281c20e89ba4b
    sa-east-1:
      AMI: ami-07b14488da8ea02a0
    us-east-1:
      AMI: ami-0ff8a91507f77f867
    us-east-2:
      AMI: ami-0b59bfac6be064b78
    us-west-1:
      AMI: ami-0bdb828fd58c52235
    us-west-2:
      AMI: ami-a0cfeed8
Resources:
  EC2Instance:
    Type: 'AWS::EC2::Instance'
    Properties:
      KeyName: !Ref KeyName
      SecurityGroups:
        - !Ref AirflowEC2SecurityGroup
      InstanceType: t3.micro
      IamInstanceProfile:
        Ref: EC2InstanceProfile
      Tags:
        - Key: Name
          Value: Airflow
      ImageId: !FindInMap 
        - RegionMap
        - !Ref 'AWS::Region'
        - AMI
      UserData:
        'Fn::Base64': !Sub >
          #!/bin/bash

          set -x

          exec > >(tee /var/log/user-data.log|logger -t user-data ) 2>&1

          # Get latest version of pip (pip 10 breaks airflow installation hence
          moving to stable pip version)

          python -m pip install pip==9.0.3 --user

          # Get the latest CloudFormation package

          echo "Installing aws-cfn"

          yum install -y aws-cfn-bootstrap

          # Start cfn-init

          /opt/aws/bin/cfn-init -v -c install --stack ${AWS::StackId} --resource
          EC2Instance --region ${AWS::Region}

          # Install git

          echo "Installing git"

          sudo yum install -y git

          # Install boto3

          echo "Updating boto3"

          python -m pip install boto3 --upgrade --user

          # Upgrade awscli

          echo "Updating awscli"

          python -m pip install awscli --upgrade --user

          python -m pip uninstall marshmallow-sqlalchemy

          python -m pip install marshmallow-sqlalchemy==0.17.1

          python -m pip install config

          # Install airflow using pip

          echo "Installing Apache Airflow"

          export AIRFLOW_GPL_UNIDECODE=yes

          python -m pip install apache-airflow --user

          # Encrypt connection passwords in metadata db

          python -m pip install apache-airflow[crypto] --user

          # Postgres operators and hook, support as an Airflow backend

          python -m pip install apache-airflow[postgres] --user

          python -m pip install six==1.10.0 --user

          python -m pip install --upgrade six --user

          python -m pip install markupsafe --user

          python -m pip install --upgrade MarkupSafe --user

          echo 'export PATH=/usr/local/bin:~/.local/bin:$PATH' >>
          ~/.bash_profile

          source ~/.bash_profile

          # Install pandas and numpy for data processing

          echo "Installing numpy"

          python -m pip install --upgrade numpy --user

          echo "Installing pandas"

          python -m pip install --upgrade pandas --user

          echo "Installing s3fs"

          python -m pip install --upgrade s3fs --user

          echo "Installing sagemaker sdk"

          python -m pip install sagemaker==v1.39.2 --user

          # Initialize Airflow

          airflow initdb

          # Update the RDS connection in the Airflow Config file

          sed -i '/sql_alchemy_conn/s/^/#/g' ~/airflow/airflow.cfg
          
          export secret_password=` aws secretsmanager get-secret-value --secret-id ${DBPassword} --region ${AWS::Region}`
          
          sed -i '/sql_alchemy_conn/ a sql_alchemy_conn =
          postgresql://airflow:$secret_password@${DBInstance.Endpoint.Address}:${DBInstance.Endpoint.Port}/airflowdb'
          ~/airflow/airflow.cfg

          # Update the type of executor in the Airflow Config file

          sed -i '/executor = SequentialExecutor/s/^/#/g' ~/airflow/airflow.cfg

          sed -i '/executor = SequentialExecutor/ a executor = LocalExecutor'
          ~/airflow/airflow.cfg

          airflow initdb

          # create airflow connection to sagemaker

          cat >> /tmp/airflow_conn.py << EOF

          from airflow import settings

          from airflow.models import Connection

          #create a connection object

          extra = '{"region_name": "${AWS::Region}"}'

          conn_id = 'airflow-sagemaker'

          conn = Connection(conn_id=conn_id,conn_type='aws', extra=extra)

          # get the session

          session = settings.Session()

          session.add(conn)

          session.commit()

          EOF

          python /tmp/airflow_conn.py

          # create directories

          mkdir -p ~/airflow/dags/sm-ml-pipeline

          # clone the git repository

          cd ~

          git clone
          https://github.com/aws-samples/sagemaker-ml-workflow-with-apache-airflow.git

          mv ~/sagemaker-ml-workflow-with-apache-airflow ~/sm-ml-pipeline

          cd ~/sm-ml-pipeline/src

          # prepare airflow dag definition for sagemaker blog post

          sed -i 's/<s3-bucket>/${S3BucketName}/g' ./*.*

          sed -i 's/<region-name>/${AWS::Region}/g' ./*.*

          zip -r dag.zip *

          cp dag.zip ~/airflow/dags/sm-ml-pipeline/dag.zip

          cd -

          # Run Airflow webserver and scheduler

          airflow list_dags

          airflow webserver -D

          airflow scheduler -D
    Metadata:
      'AWS::CloudFormation::Init':
        configSets:
          install:
            - gcc
        gcc:
          packages:
            yum:
              gcc: []
      'AWS::CloudFormation::Designer':
        id: aa91712f-7347-46c7-850e-560721812c4d
    DependsOn:
      - DBInstance
      - AirflowEC2SecurityGroup
      - DBPassword
  DBPassword:
    Type: 'AWS::SecretsManager::Secret'
    Properties:
      Description: This is the secret for my RDS instance
      GenerateSecretString:
        SecretStringTemplate: '{"username": "airflow"}'
        GenerateStringKey: password
        PasswordLength: 24
        ExcludeCharacters: '"@/\'
    Metadata:
      'AWS::CloudFormation::Designer':
        id: c4573bc1-8c6d-40cc-88ee-2068d8bb7560
  DBInstance:
    Type: 'AWS::RDS::DBInstance'
    DeletionPolicy: Delete
    Properties:
      DBName: airflowdb
      Engine: postgres
      MasterUsername: airflow
      MasterUserPassword: !Join ['', ['{{resolve:secretsmanager:', !Ref DBPassword, ':SecretString:password}}' ]]
      DBInstanceClass: db.t2.micro
      AllocatedStorage: 5
      DBSecurityGroups:
        - Ref: DBSecurityGroup
    Metadata:
      'AWS::CloudFormation::Designer':
        id: cd9ba412-c66d-4fac-81c0-1fcc7b7425ef
  AirflowEC2SecurityGroup:
    Type: 'AWS::EC2::SecurityGroup'
    Properties:
      GroupName: AirflowEC2SG
      GroupDescription: Enable HTTP access via port 80 + SSH access
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 8080
          ToPort: 8080
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0
    Metadata:
      'AWS::CloudFormation::Designer':
        id: db9f009e-115d-4829-aedb-fa00587a3986
  DBSecurityGroup:
    Type: 'AWS::RDS::DBSecurityGroup'
    Properties:
      GroupDescription: Frontend Access
      DBSecurityGroupIngress:
        EC2SecurityGroupName:
          Ref: AirflowEC2SecurityGroup
    Metadata:
      'AWS::CloudFormation::Designer':
        id: 8378ad56-2e38-46ab-9384-0a39a71b68a4
  EC2Role:
    Type: 'AWS::IAM::Role'
    Properties:
      RoleName: AirflowInstanceRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ec2.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/AmazonSageMakerFullAccess'
      Policies:
        - PolicyName: AirflowResourceAccess
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 's3:*'
                Resource:
                  - !Sub 'arn:aws:s3:::${S3BucketName}'
                  - !Sub 'arn:aws:s3:::${S3BucketName}/*'
              - Effect: Allow
                Action:
                  - 'iam:GetRole'
                Resource: '*'
    Metadata:
      'AWS::CloudFormation::Designer':
        id: d9a68053-22ad-48a6-82be-d801dbedecda
  EC2InstanceProfile:
    Type: 'AWS::IAM::InstanceProfile'
    Properties:
      InstanceProfileName: AirflowInstanceProfile
      Roles:
        - Ref: EC2Role
    Metadata:
      'AWS::CloudFormation::Designer':
        id: bbd70c52-255c-4cda-a2fa-9de0cd4e81a4
  S3Bucket:
    Type: 'AWS::S3::Bucket'
    DeletionPolicy: Retain
    Properties:
      AccessControl: BucketOwnerFullControl
      BucketName: !Ref S3BucketName
    Metadata:
      'AWS::CloudFormation::Designer':
        id: eab0fdc0-387f-4442-9856-70e985c83551
Outputs:
  AirflowEC2PublicDNSName:
    Description: Public DNS Name of the Airflow EC2 instance
    Value: !Join 
      - ''
      - - 'http://'
        - !GetAtt EC2Instance.PublicDnsName
        - ':8080'
Metadata:
  'AWS::CloudFormation::Designer':
    eab0fdc0-387f-4442-9856-70e985c83551:
      size:
        width: 60
        height: 60
      position:
        x: 60
        'y': 90
      z: 1
      embeds: []
    d9a68053-22ad-48a6-82be-d801dbedecda:
      size:
        width: 60
        height: 60
      position:
        x: 180
        'y': 90
      z: 1
      embeds: []
    bbd70c52-255c-4cda-a2fa-9de0cd4e81a4:
      size:
        width: 60
        height: 60
      position:
        x: 60
        'y': 210
      z: 1
      embeds: []
      isassociatedwith:
        - d9a68053-22ad-48a6-82be-d801dbedecda
    db9f009e-115d-4829-aedb-fa00587a3986:
      size:
        width: 60
        height: 60
      position:
        x: 180
        'y': 210
      z: 1
      embeds: []
    8378ad56-2e38-46ab-9384-0a39a71b68a4:
      size:
        width: 60
        height: 60
      position:
        x: 300
        'y': 90
      z: 1
      embeds: []
    cd9ba412-c66d-4fac-81c0-1fcc7b7425ef:
      size:
        width: 60
        height: 60
      position:
        x: 300
        'y': 210
      z: 1
      embeds: []
      isassociatedwith:
        - 8378ad56-2e38-46ab-9384-0a39a71b68a4
    aa91712f-7347-46c7-850e-560721812c4d:
      size:
        width: 60
        height: 60
      position:
        x: 60
        'y': 330
      z: 1
      embeds: []
      dependson:
        - cd9ba412-c66d-4fac-81c0-1fcc7b7425ef
        - db9f009e-115d-4829-aedb-fa00587a3986
    c4573bc1-8c6d-40cc-88ee-2068d8bb7560:
      size:
        width: 60
        height: 60
      position:
        x: 150
        'y': 300
      z: 1
      embeds: []
